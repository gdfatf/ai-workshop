from __future__ import annotations

from pathlib import Path
import os

import streamlit as st

# LangChain + Gemini
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings

# LangChain core
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.documents import Document

# RAG / Vector DB
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import Chroma

# DOCX loader
from docx import Document as DocxDocument


# =========================
# Streamlit åŸºç¡€è®¾ç½®
# =========================
st.set_page_config(page_title="AI Workbench Â· Gemini", layout="wide")
st.title("ğŸ§° AI Workbench Â· 13 Agents + RAGï¼ˆGemini 3 Proï¼‰")


# =========================
# Secrets è¯»å–ï¼ˆStreamlit Cloudï¼‰
# =========================
from dotenv import load_dotenv
load_dotenv()

def sget(key: str, default: str | None = None) -> str | None:
    # å…ˆå°è¯•è¯» Streamlit Cloud secretsï¼ˆå¦‚æœæœ¬åœ°æ²¡æœ‰ secrets.tomlï¼Œä¼šæŠ› FileNotFoundErrorï¼‰
    try:
        if key in st.secrets:
            return str(st.secrets[key])
    except FileNotFoundError:
        pass  # æœ¬åœ°æ²¡ secrets.toml å¾ˆæ­£å¸¸

    # æœ¬åœ°å…œåº•ï¼šè¯»ç¯å¢ƒå˜é‡ï¼ˆ.env å·² load_dotenvï¼‰
    return os.getenv(key, default)



GOOGLE_API_KEY = sget("GOOGLE_API_KEY")
GEMINI_MODEL = sget("GEMINI_MODEL", "gemini-3-pro-preview")
APP_PASSWORD = sget("APP_PASSWORD", "")

if not GOOGLE_API_KEY:
    st.error("ç¼ºå°‘ GOOGLE_API_KEYï¼šè¯·åœ¨ Streamlit Cloud çš„ Secrets é‡Œé…ç½® GOOGLE_API_KEYã€‚")
    st.stop()


# =========================
# ç®€å•å¯†ç é—¨ï¼ˆå¯é€‰ï¼‰
# =========================
if APP_PASSWORD:
    if "authed" not in st.session_state:
        st.session_state.authed = False

    if not st.session_state.authed:
        with st.container():
            st.subheader("ğŸ”’ è¯·è¾“å…¥è®¿é—®å¯†ç ")
            pwd = st.text_input("Password", type="password")
            if st.button("è¿›å…¥"):
                if pwd == APP_PASSWORD:
                    st.session_state.authed = True
                    st.rerun()
                else:
                    st.error("å¯†ç ä¸æ­£ç¡®")
        st.stop()


# =========================
# è·¯å¾„ä¸ç›®å½•
# =========================
PROMPTS_DIR = Path("agents") / "prompts"
KB_DIR = Path("kb")
DB_DIR = Path(".chroma_db")  # Streamlit Cloud: æŒä¹…åŒ–åœ¨å®¹å™¨å†…ï¼ˆé‡å¯å¯èƒ½ä¸¢å¤±ï¼Œä½†è¿è¡Œä¸­å¯ç”¨ï¼‰

PROMPTS_DIR.mkdir(parents=True, exist_ok=True)
KB_DIR.mkdir(parents=True, exist_ok=True)
DB_DIR.mkdir(parents=True, exist_ok=True)


AGENTS = {
    "01 äººè®¾å®šä½ Agent": "agent_01.txt",
    "02 åŸåˆ›çµæ„Ÿè®¨è®º Agent": "agent_02.txt",
    "03 çˆ†æ¬¾å†…å®¹ç­–åˆ’ Agent": "agent_03.txt",
    "04 æ–‡æ¡ˆèµŒæ³¨å¼ºåŒ– Agent": "agent_04.txt",
    "05 æ–‡æ¡ˆå¼€å¤´å¼ºåŒ– Agent": "agent_05.txt",
    "06 å†…å®¹äººæ ¼é­…åŠ›å¼ºåŒ– Agent": "agent_06.txt",
    "07 æ–‡æ¡ˆç”¨æˆ·éœ€æ±‚å¼ºåŒ– Agent": "agent_07.txt",
    "08 çº¿ç´¢è½¬åŒ–ç±»å†…å®¹ç­–åˆ’ Agent": "agent_08.txt",
    "09 å†…å®¹å½±åƒè®¾è®¡ Agent": "agent_09.txt",
    "10 å¤§çº²ç»“æ„ç»„ç»‡ Agent": "agent_10.txt",
    "11 å†…å®¹éª¨æ¶æ­å»º Agent": "agent_11.txt",
    "12 æ•´ä½“æ–‡æ¡ˆæ”¹å†™ Agent": "agent_12.txt",
    "13 ä¸ªäººIPè´¦å·è¿è¥é—®é¢˜è¯Šæ–­ Agent": "agent_13.txt",
}


# =========================
# å·¥å…·å‡½æ•°
# =========================
def load_prompt(filename: str) -> str:
    path = PROMPTS_DIR / filename
    if not path.exists():
        return "You are a helpful assistant."
    txt = path.read_text(encoding="utf-8").strip()
    return txt or "You are a helpful assistant."


def load_docx_text(path: Path) -> str:
    doc = DocxDocument(str(path))
    parts = [p.text for p in doc.paragraphs if p.text.strip()]
    return "\n".join(parts)


def load_kb_documents(agent_id: str) -> list[Document]:
    """
    ä» kb/agent_XX/ è¯»å– docx/txtï¼Œç»Ÿä¸€æˆ LangChain Document
    """
    folder = KB_DIR / agent_id
    folder.mkdir(parents=True, exist_ok=True)

    docs: list[Document] = []
    for p in folder.rglob("*"):
        if p.is_dir():
            continue

        if p.suffix.lower() == ".txt":
            docs.extend(TextLoader(str(p), encoding="utf-8").load())

        elif p.suffix.lower() == ".docx":
            text = load_docx_text(p)
            docs.append(Document(page_content=text, metadata={"source": str(p)}))

    return docs


def build_embeddings() -> GoogleGenerativeAIEmbeddings:
    # Google å®˜æ–¹ embeddingsï¼šå¸¸è§å¯ç”¨å
    # - "models/embedding-001"
    # æŸäº›æ–‡æ¡£/ç¤ºä¾‹ä¼šå†™ "gemini-embedding-001"ï¼ˆä¸åŒ SDK/æ—¶æœŸå‘½åå¯èƒ½å˜åŒ–ï¼‰
    # è¿™é‡Œç”¨æ›´å¸¸è§çš„ models/embedding-001
    return GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=GOOGLE_API_KEY,
    )


@st.cache_resource(show_spinner=False)
def get_vectorstore(agent_id: str) -> Chroma:
    """
    æ¯ä¸ª agent ä¸€ä¸ª Chroma ç´¢å¼•ï¼ˆæœ¬åœ°æŒä¹…åŒ–ç›®å½•ï¼‰ã€‚
    kb ä¸ºç©ºä¹Ÿèƒ½æ­£å¸¸è¿”å›ç©ºåº“ã€‚
    """
    embeddings = build_embeddings()

    persist_dir = DB_DIR / agent_id
    persist_dir.mkdir(parents=True, exist_ok=True)

    vs = Chroma(
        collection_name=f"kb_{agent_id}",
        embedding_function=embeddings,
        persist_directory=str(persist_dir),
    )

    # å¦‚æœåº“ä¸ºç©ºå°±å†™å…¥
    try:
        existing = vs._collection.count()
    except Exception:
        existing = 0

    if existing == 0:
        raw_docs = load_kb_documents(agent_id)
        if raw_docs:
            splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=120)
            chunks = splitter.split_documents(raw_docs)
            vs.add_documents(chunks)
            try:
                vs.persist()
            except Exception:
                pass

    return vs


def retrieve_context(agent_id: str, query: str, k: int = 4) -> str:
    vs = get_vectorstore(agent_id)

    try:
        docs = vs.similarity_search(query, k=k)
    except Exception:
        docs = []

    if not docs:
        return ""

    blocks = []
    for i, d in enumerate(docs, 1):
        src = d.metadata.get("source", "kb")
        blocks.append(f"[ç‰‡æ®µ{i} | æ¥æº: {src}]\n{d.page_content}")
    return "\n\n".join(blocks)


def build_llm(model_name: str, temperature: float) -> ChatGoogleGenerativeAI:
    return ChatGoogleGenerativeAI(
        model=model_name,
        temperature=temperature,
        google_api_key=GOOGLE_API_KEY,
    )


# =========================
# Sidebar UI
# =========================
with st.sidebar:
    st.header("è®¾ç½®")

    st.write("Gemini Key exists:", True)
    st.write("Gemini Model (default):", GEMINI_MODEL)

    agent_name = st.selectbox("é€‰æ‹© Agent", list(AGENTS.keys()))

    # æ¨¡å‹ï¼šç»™ä½ ä¸€ä¸ªå¯é€‰ä¸‹æ‹‰ï¼ˆé»˜è®¤ Gemini 3 Proï¼‰
    model_name = st.selectbox(
        "æ¨¡å‹",
        ["gemini-3-pro-preview", "gemini-3-flash-preview", "gemini-1.5-pro", "gemini-1.5-flash"],
        index=0 if GEMINI_MODEL not in ["gemini-3-pro-preview", "gemini-3-flash-preview", "gemini-1.5-pro", "gemini-1.5-flash"]
        else ["gemini-3-pro-preview", "gemini-3-flash-preview", "gemini-1.5-pro", "gemini-1.5-flash"].index(GEMINI_MODEL),
    )

    temperature = st.slider("temperature", 0.0, 1.0, 0.3, 0.05)

    use_rag = st.toggle("å¯ç”¨ RAGï¼ˆä» kb æ£€ç´¢ï¼‰", value=True)
    topk = st.slider("æ£€ç´¢ TopK", 1, 8, 4, 1)

    if st.button("æ¸…ç©ºå½“å‰ Agent å¯¹è¯"):
        st.session_state.pop(f"chat::{agent_name}", None)
        st.rerun()

    st.divider()
    st.caption("ğŸ“Œ çŸ¥è¯†åº“ç›®å½•ï¼škb/agent_01 ~ kb/agent_13ï¼ˆdocx/txtï¼‰")
    st.caption("ğŸ“Œ Prompt ç›®å½•ï¼šagents/prompts/agent_01.txt ~ agent_13.txt")


# =========================
# ä¸»æµç¨‹
# =========================
agent_file = AGENTS[agent_name]
system_prompt = load_prompt(agent_file)
agent_id = agent_file.replace(".txt", "")  # agent_01 ... agent_13

llm = build_llm(model_name=model_name, temperature=temperature)

chat_key = f"chat::{agent_name}"
if chat_key not in st.session_state:
    st.session_state[chat_key] = []
chat = st.session_state[chat_key]

with st.expander("æŸ¥çœ‹å½“å‰ Agent çš„ System Promptï¼ˆåªè¯»ï¼‰", expanded=False):
    st.code(system_prompt)

for msg in chat:
    if isinstance(msg, HumanMessage):
        with st.chat_message("user"):
            st.markdown(msg.content)
    else:
        with st.chat_message("assistant"):
            st.markdown(msg.content)

user_text = st.chat_input(f"æ­£åœ¨ä½¿ç”¨ï¼š{agent_name}ï¼ˆå¯ç²˜è´´é•¿æ–‡æœ¬ï¼‰")

if user_text:
    chat.append(HumanMessage(content=user_text))
    with st.chat_message("user"):
        st.markdown(user_text)

    rag_context = ""
    if use_rag:
        rag_context = retrieve_context(agent_id, user_text, k=topk)

    sys = system_prompt
    if rag_context:
        sys = (
            system_prompt
            + "\n\nã€å¯å¼•ç”¨çŸ¥è¯†åº“ç‰‡æ®µã€‘\n"
            + rag_context
            + "\n\nè¦æ±‚ï¼šå¦‚æœå¼•ç”¨äº†ç‰‡æ®µï¼Œè¯·åœ¨å›ç­”ä¸­æ ‡æ³¨æ¥æºç‰‡æ®µç¼–å·ã€‚"
        )

    messages = [SystemMessage(content=sys)] + chat

    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­â€¦"):
            resp = llm.invoke(messages)
            st.markdown(resp.content)

    chat.append(AIMessage(content=resp.content))


# =========================
# å³ä¾§ï¼šè¾…åŠ©é¢æ¿ï¼ˆå¯é€‰ï¼‰
# =========================
with st.expander("ğŸ§ª è°ƒè¯•é¢æ¿", expanded=False):
    st.write("å½“å‰ Agentï¼š", agent_name)
    st.write("agent_idï¼š", agent_id)
    st.write("æ¨¡å‹ï¼š", model_name)
    st.write("RAGï¼š", use_rag, "TopK=", topk)
